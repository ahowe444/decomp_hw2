{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import islice\n",
    "\n",
    "from decomp import UDSCorpus\n",
    "uds_train = UDSCorpus(split='train')\n",
    "uds_dev = UDSCorpus(split='dev')\n",
    "uds_test = UDSCorpus(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(results, base):\n",
    "    d = []\n",
    "    for sentence, graph in base.items():\n",
    "        for tuple_, data in graph.semantics_edges().items():\n",
    "            if 'protoroles' in data.keys():\n",
    "                pred = tuple_[0]\n",
    "                arg = tuple_[1]\n",
    "                arg_position, _ = base[sentence].head(arg, ['form', 'lemma'])\n",
    "                pred_position, _ = base[sentence].head(pred, ['form', 'lemma'])\n",
    "                syntax_nodes = base[sentence].syntax_nodes.values()\n",
    "                tokens = [node['form'] for node in syntax_nodes]\n",
    "                tokens.append(pred_position)\n",
    "                tokens.append(arg_position)\n",
    "                \n",
    "                if len(results[sentence]) == 0:\n",
    "                    tokens.append(0)\n",
    "                else:\n",
    "                    if tuple_ in results[sentence].keys():\n",
    "                        tokens.append(1)\n",
    "                    else:\n",
    "                        tokens.append(0)\n",
    "                d.append(tokens)                 \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentstr = \"\"\"\n",
    "           SELECT ?edge\n",
    "           WHERE { ?edge <existed_before> ?existedbefore\n",
    "                           FILTER (?existedbefore > 0 ) .\n",
    "                   { ?edge <volition> ?volition\n",
    "                           FILTER ( ?volition > 0 ) .\n",
    "                   } UNION\n",
    "                   { ?edge <instigation> ?instigation\n",
    "                           FILTER ( ?instigation > 0 ) .\n",
    "                   }\n",
    "                 }\n",
    "           \"\"\"\n",
    "\n",
    "agent_train_results = {gid: graph.query(agentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_train.items()}\n",
    "\n",
    "agent_dev_results = {gid: graph.query(agentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_dev.items()}\n",
    "\n",
    "agent_test_results = {gid: graph.query(agentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = build_dataset(agent_train_results, uds_train)\n",
    "with open(\"agent_train.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(agent_dev_results, uds_dev)\n",
    "with open(\"agent_dev.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(agent_test_results, uds_test)\n",
    "with open(\"agent_test.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientstr = \"\"\"\n",
    "           SELECT ?edge\n",
    "           WHERE { ?edge <existed_before> ?existedbefore\n",
    "                            FILTER ( ?existedbefore > 0 ) .                     \n",
    "                    { ?edge <volition> ?volition\n",
    "                            FILTER ( ?volition < 0 ) .\n",
    "                    } UNION\n",
    "                    { ?edge <instigation> ?instigation\n",
    "                            FILTER ( ?instigation < 0 ) .\n",
    "                    }\n",
    "                 }\n",
    "           \"\"\"\n",
    "\n",
    "patient_train_results = {gid: graph.query(patientstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_train.items()}\n",
    "\n",
    "patient_dev_results = {gid: graph.query(patientstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_dev.items()}\n",
    "\n",
    "patient_test_results = {gid: graph.query(patientstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = build_dataset(patient_train_results, uds_train)\n",
    "with open(\"patient_train.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(patient_dev_results, uds_dev)\n",
    "with open(\"patient_dev.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(patient_test_results, uds_test)\n",
    "with open(\"patient_test.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentstr = \"\"\"\n",
    "           SELECT ?edge\n",
    "           WHERE { ?edge <was_used> ?wasused\n",
    "                            FILTER ( ?wasused > 0 ) .                     \n",
    "                   ?edge <existed_during> ?existedduring\n",
    "                            FILTER ( ?existedduring > 0 ) .\n",
    "                    { ?edge <sentient> ?sentient\n",
    "                            FILTER ( ?sentient < 0 ) . \n",
    "                    } UNION\n",
    "                    { ?edge <awareness> ?awareness\n",
    "                            FILTER ( ?awareness < 0 ) .\n",
    "                    }\n",
    "                 }\n",
    "           \"\"\"\n",
    "\n",
    "instrument_train_results = {gid: graph.query(instrumentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_train.items()}\n",
    "\n",
    "instrument_dev_results = {gid: graph.query(instrumentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_dev.items()}\n",
    "\n",
    "instrument_test_results = {gid: graph.query(instrumentstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = build_dataset(instrument_train_results, uds_train)\n",
    "with open(\"instrument_train.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(instrument_dev_results, uds_dev)\n",
    "with open(\"instrument_dev.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(instrument_test_results, uds_test)\n",
    "with open(\"instrument_test.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultstr = \"\"\"\n",
    "           SELECT ?edge\n",
    "           WHERE { ?edge <existed_before> ?existedbefore\n",
    "                            FILTER ( ?existedbefore < 0 ) .\n",
    "                   ?edge <existed_after> ?existedafter\n",
    "                            FILTER ( ?existedafter > 0 ) .\n",
    "                   ?edge <change_of_state> ?changeofstate\n",
    "                            FILTER ( ?changeofstate > 0 ) .\n",
    "                 }\n",
    "           \"\"\"\n",
    "\n",
    "result_train_results = {gid: graph.query(resultstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_train.items()}\n",
    "\n",
    "result_dev_results = {gid: graph.query(resultstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_dev.items()}\n",
    "\n",
    "result_test_results = {gid: graph.query(resultstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = build_dataset(result_train_results, uds_train)\n",
    "with open(\"result_train.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(result_dev_results, uds_dev)\n",
    "with open(\"result_dev.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(result_test_results, uds_test)\n",
    "with open(\"result_test.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationstr = \"\"\"\n",
    "           SELECT ?edge\n",
    "           WHERE { ?edge <location> ?location\n",
    "                            FILTER ( ?location > 0 ) .\n",
    "                   ?edge <change_of_location> ?changeoflocation\n",
    "                            FILTER ( ?changeoflocation > 0 ) .\n",
    "                   ?edge <existed_before> ?existedbefore\n",
    "                            FILTER ( ?existedbefore > 0 ) .\n",
    "                 }\n",
    "           \"\"\"\n",
    "\n",
    "dest_train_results = {gid: graph.query(destinationstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_train.items()}\n",
    "\n",
    "dest_dev_results = {gid: graph.query(destinationstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_dev.items()}\n",
    "\n",
    "dest_test_results = {gid: graph.query(destinationstr, query_type='edge', cache_rdf=False)\n",
    "           for gid, graph in uds_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = build_dataset(dest_train_results, uds_train)\n",
    "with open(\"dest_train.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(dest_dev_results, uds_dev)\n",
    "with open(\"dest_dev.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)\n",
    "    \n",
    "d = build_dataset(dest_test_results, uds_test)\n",
    "with open(\"dest_test.data\", 'wb') as filename:\n",
    "    pickle.dump(d, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for instance in d:\n",
    "    if instance[-1] == 1:\n",
    "        count+=1\n",
    "        \n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
